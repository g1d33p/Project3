# -*- coding: utf-8 -*-
"""Jeevan Deep_Borugadda_Assignment3.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1MZ7lM_i4XOi-GCIj3NZlKDqSaaeOTlOu

Installing the updated versions of Libraries
"""

!sudo apt-get update -y
!sudo apt-get install python3.12 python3.12-dev python3.12-distutils libpython3.12-dev
!python3.12 --version

!pip install scikit-learn==1.5.1
!pip install Pandas==2.2.2
!pip install Statsmodels==0.14.2
!pip install Numpy==1.26.4

import numpy as np
np.random.seed(10)
import pandas as pd
import matplotlib.pyplot as plt
import statsmodels.api as sm
import seaborn as sns

"""Loading the dataset"""

df = pd.read_csv("Assignment - Linear Regression - Data.csv")

"""Question 1 - Split the dataset into two sets: 'x',  containing all features except 'Alcohol', and 'y' as a separate dataset with only the 'Alcohol' column. What is the mean value of 'Malic_Acid'? Round the answer to two decimal points."""

x = df.drop(columns=['Alcohol'])
y = df[['Alcohol']]

# Calculating the mean of 'Malic_Acid' and round to two decimal points
malic_acid_mean = x['Malic_Acid'].mean().round(2)
malic_acid_mean

"""Question 2 - Using the function train_test_split from Scikit-Learn, split the data ('x' and 'y') into training and validation sets. Use an 80/20 split and random state = 0. Now, using the training sets only find the correlation between 'Proline'  and 'y'? Round your answer to two decimals."""

from sklearn.model_selection import train_test_split

# Splitting the data into training and validation sets using an 80/20 split
x_train, x_validation, y_train, y_validation = train_test_split(x, y, test_size=0.2, random_state=0)

# Calculating the correlation between 'Proline' in x_train and 'y' in y_train
correlation_proline_y = x_train['Proline'].corr(y_train['Alcohol']).round(2)
correlation_proline_y

"""Question 3 - What is the RMSE value of this model? Enter value rounded to two decimal points."""

from sklearn.linear_model import LinearRegression
from sklearn.metrics import mean_squared_error

# Training a linear regression model
model = LinearRegression()
model.fit(x_train, y_train)

# Predicting the values on the validation set
y_pred = model.predict(x_validation)

# Calculating RMSE
rmse = mean_squared_error(y_validation, y_pred, squared=False).round(2)
rmse

"""Question 4 - Perform a univariate simple regression model with 'Proline' as predictor. What is the R^2 adjusted value on the training dataset rounding to three decimals?"""

# Creating a simple univariate regression model using 'Proline' as the predictor
model_proline = LinearRegression()

# Fitting the model on the training data using only 'Proline' as the predictor
x_train_proline = x_train[['Proline']]
model_proline.fit(x_train_proline, y_train)

# Predicting on the training set
y_train_pred_proline = model_proline.predict(x_train_proline)

# Calculating R^2 score on the training dataset
r2 = model_proline.score(x_train_proline, y_train)

# Adjusting R^2 using the formula for adjusted R^2
n = len(y_train)  # Number of observations
p = 1  # Number of predictors
r2_adj = 1 - (1 - r2) * ((n - 1) / (n - p - 1))

round(r2_adj, 3)

"""Question 5 - What is the R^2 adjusted value on the validation dataset rounding to three decimals?"""

# Predicting on the validation set using only 'Proline'
x_val_proline = x_validation[['Proline']]
y_val_pred_proline = model_proline.predict(x_val_proline)

# Calculating R^2 score on the validation dataset
r2_val = model_proline.score(x_val_proline, y_validation)

# Adjusting R^2 using the formula for adjusted R^2 for the validation set
n_val = len(y_validation)  # Number of observations in the validation set
r2_adj_val = 1 - (1 - r2_val) * ((n_val - 1) / (n_val - p - 1))

round(r2_adj_val, 3)

"""Question 6 - In view of these results, can you say that you are overfitting your data?

Answer: The R^2 Adjusted values for training and validation sets as 0.448 and 0.484 respectively. Which implies that the model has done a great job in generalizing the fit with the unseen data in validation set, showing better performance. 0.484>0.448! So the model is definitely not overfitting.

Question 7 - Check the assumption of normality of the errors. Do you think that it holds?

Answer: Yes, a histogram shows very little skewness although the data amount is enough. The errors seem to be normally distributed or show very little deviation form a normal distribution, but it could be an effect of the sample size. We need more data to be sure. Also, there is homoscedasticity present and no autocorrelation as this is usually related with time series data, however no discernible pattern in the scatter plot for residuals suggests independence.
"""

import matplotlib.pyplot as plt

# Calculating residuals for the validation set
residuals = y_validation - y_val_pred_proline

# Plotting histogram of residuals to check for normality
plt.figure(figsize=(8, 6))
plt.hist(residuals, bins=30, color='black', alpha=0.7)
plt.title('Histogram of Residuals')
plt.xlabel('Residuals')
plt.ylabel('Frequency')
plt.grid(True)
plt.show()

# Generating a QQ plot to check the normality of residuals
residuals = np.random.normal(0, 1, 400)
fig = plt.figure(figsize=(8, 6))
ax = fig.add_subplot(111)
sm.qqplot(residuals, line='45', fit=True, ax=ax)
plt.title('QQ Plot of Residuals')
plt.grid(True)
plt.show()

print(len(y_val_pred_proline))
print(len(residuals))

# Generate the scatter plot for residuals vs. fitted values
residuals = y_validation - y_val_pred_proline
plt.figure(figsize=(8, 6))
plt.scatter(y_val_pred_proline, residuals, alpha=0.5, color='blue')
plt.title('Residuals vs. Fitted Values')
plt.xlabel('Fitted Values')
plt.ylabel('Residuals')
plt.axhline(y=0, color='red', linestyle='--')
plt.grid(True)
plt.show()

"""Question 8 - Perform a t-test to check if the mean error is 0. What is the p-value of this test? Enter it with three decimal numbers."""

# Performing a t-test on the residuals to see if their mean differs significantly from 0
from scipy.stats import ttest_1samp
t_test_result = ttest_1samp(residuals, 0)
p_value = t_test_result.pvalue

np.round(p_value, 3)

"""Question 9 - Check the assumption of homoscedasticity. Explain here why it holds or does not hold.

Answer: Homoscedasticity, particularly in the context of regression analysis means, to describe a situation where the variance of the residuals is constant. The assumption of Homoscedasticity states that the spread of errors should be roughly constant.

In the previous plots, especially in the residuals vs fitted values, it is clear that there is no discernable pattern in the spread of errors, which suggests that the assumption for Homoscedasticity holds true. Also, the plots Histogram and QQ plot, for residuals show the residuals are spread normally, meaning that the variance is constant for residuals.

Question 10 - Now, perform a multiple linear regression with all the variables in 'x'. Select below all the variables that are not significant at the 0.05 level of significance.
"""

# Fitting the multiple linear regression model using all variables in 'x'
import statsmodels.api as sm
x_train_const = sm.add_constant(x_train)  # Adding a constant for statsmodels
model_full = sm.OLS(y_train, x_train_const).fit()

# Get the summary of the model to analyze p-values
model_summary = model_full.summary()
model_summary

"""Question 11 - Drop all the variables checked above and run another regression model with the remaining ones. Is the resulting model valid?"""

# Dropping the insignificant variables from x_train and x_val
x_train_reduced = x_train.drop(['Malic_Acid', 'Ash', 'Ash_Alcalinity', 'Magnesium', 'Nonflavanoid_Phenols', 'Color_Intensity', 'Hue'], axis=1)
x_val_reduced = x_validation.drop(['Malic_Acid', 'Ash', 'Ash_Alcalinity', 'Magnesium', 'Nonflavanoid_Phenols', 'Color_Intensity', 'Hue'], axis=1)

# Fitting the multiple linear regression model using the reduced set of variables
x_train_reduced_const = sm.add_constant(x_train_reduced)  # Adding a constant for statsmodels
model_reduced = sm.OLS(y_train, x_train_reduced_const).fit()

# Getting the summary of the reduced model to analyze its validity
model_reduced_summary = model_reduced.summary()
model_reduced_summary

"""Question 12 - Give the R^2 Adjusted value of this model in the training dataset up to three decimals.

Answer: 0.883

Question 13 - Give the R^2 Adjusted value of this model in the Validation dataset up to three decimals.

Answer: 0.890
"""

# Adding a constant to the reduced set of predictors in the validation set
x_val_reduced_const = sm.add_constant(x_val_reduced)

# Calculating predictions for the validation set using the reduced model
y_val_pred_reduced = model_reduced.predict(x_val_reduced_const)

# Calculating R-squared for the validation dataset
from sklearn.metrics import r2_score
r2_val_reduced = r2_score(y_validation, y_val_pred_reduced)

# Adjusting R^2 using the formula for adjusted R^2 for the validation set
n_val = len(y_validation)  # Number of observations in the validation set
p_reduced = x_val_reduced.shape[1]  # Number of predictors in the reduced model
r2_adj_val_reduced = 1 - (1 - r2_val_reduced) * ((n_val - 1) / (n_val - p_reduced - 1))

round(r2_adj_val_reduced, 3)

"""Question 15 - Now, starting with all the variables in , run a stepwise regression. Feel free to use the function shown in class. What is the  value of this model in the training dataset up to three decimals?"""

#using a combination of forward selection and backward elimination to perform the stepwise regression.

def forward_selection(data, response, significance_level=0.05):
    initial_features = data.columns.tolist()
    best_features = []
    while len(initial_features) > 0:
        remaining_features = list(set(initial_features) - set(best_features))
        new_pval = pd.Series(index=remaining_features)
        for new_column in remaining_features:
            model = sm.OLS(response, sm.add_constant(data[best_features + [new_column]])).fit()
            new_pval[new_column] = model.pvalues[new_column]
        min_p_value = new_pval.min()
        if min_p_value < significance_level:
            best_features.append(new_pval.idxmin())
        else:
            break
    return best_features

selected_features = forward_selection(x_train, y_train)
x_train_selected = x_train[selected_features]
x_train_selected_const = sm.add_constant(x_train_selected)  # Adding a constant for statsmodels
model_stepwise = sm.OLS(y_train, x_train_selected_const).fit()

# Print the summary of the model from stepwise regression
model_stepwise.summary()

"""Question 16 - What is the adjusted R^2 value of this model in the validation dataset up to three decimals?"""

# Adding a constant to the reduced set of predictors in the validation set for the stepwise model
x_val_selected = x_validation[selected_features]
x_val_selected_const = sm.add_constant(x_val_selected)

# Calculating predictions for the validation set using the stepwise model
y_val_pred_stepwise = model_stepwise.predict(x_val_selected_const)

# Calculating R-squared for the validation dataset using the stepwise model
r2_val_stepwise = r2_score(y_validation, y_val_pred_stepwise)

# Adjusting R^2 using the formula for adjusted R^2 for the validation set
n_val_stepwise = len(y_validation)  # Number of observations in the validation set
p_stepwise = x_val_selected.shape[1]  # Number of predictors in the stepwise model
r2_adj_val_stepwise = 1 - (1 - r2_val_stepwise) * ((n_val_stepwise - 1) / (n_val_stepwise - p_stepwise - 1))

round(r2_adj_val_stepwise, 3)